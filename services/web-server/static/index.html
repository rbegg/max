<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Streaming ASR Client</title>
    <link rel="stylesheet" href="/static/style.css">
</head>
<body>
    <div id="container">
        <h1>Real-time Speech Transcription</h1>
        <div id="status">Press Start to begin</div>
        <div id="vad-indicator" title="Voice Activity Indicator"></div>

        <div id="vad-settings">
            <div>
                <label for="threshold">Speech Threshold:</label>
                <input type="range" id="threshold" min="0.3" max="0.9" step="0.05" value="0.5">
                <span id="threshold-value">0.50</span>
            </div>
            <div>
                <label for="pause-duration">Pause Duration (ms):</label>
                <input type="range" id="pause-duration" min="100" max="2000" step="50" value="480">
                <span id="duration-value">480 ms</span>
            </div>
        </div>

        <div id="controls">
            <button id="startButton">Start Recording</button>
            <button id="stopButton" disabled>Stop Recording</button>
        </div>
        <div id="transcription">
            <p>Transcription will appear here...</p>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.9/dist/bundle.min.js"></script>

    <script>
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const statusDiv = document.getElementById('status');
        const transcriptionDiv = document.getElementById('transcription');
        const vadIndicator = document.getElementById('vad-indicator');

        const thresholdInput = document.getElementById('threshold');
        const thresholdValueSpan = document.getElementById('threshold-value');
        const pauseDurationInput = document.getElementById('pause-duration');
        const durationValueSpan = document.getElementById('duration-value');

        let websocket;
        let micVad;
        let isRecording = false;

        // Update display values when sliders are moved
        thresholdInput.addEventListener('input', () => {
            thresholdValueSpan.textContent = parseFloat(thresholdInput.value).toFixed(2);
        });

        pauseDurationInput.addEventListener('input', () => {
            durationValueSpan.textContent = `${pauseDurationInput.value} ms`;
        });


        function connectWebSocket() {
            return new Promise((resolve, reject) => {
                const wsProtocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
                const wsUrl = `${wsProtocol}//${window.location.host}/ws`;

                statusDiv.textContent = `Connecting to server at ${wsUrl}...`;
                console.log(`Attempting to connect to WebSocket at: ${wsUrl}`);

                websocket = new WebSocket(wsUrl);

                websocket.onopen = () => {
                    console.log('WebSocket connection established.');
                    statusDiv.textContent = 'Connected. Speak into your microphone.';
                    resolve();
                };

                websocket.onmessage = (event) => {
                    const transcription = event.data;
                    if (transcription) {
                        const p = transcriptionDiv.querySelector('p');
                        const currentText = p.textContent;
                        if (currentText === "Transcription will appear here...") {
                             p.textContent = transcription + " ";
                        } else {
                             p.textContent += transcription + " ";
                        }
                    }
                };

                websocket.onerror = (error) => {
                    console.error('WebSocket error:', error);
                    statusDiv.textContent = 'Error connecting to the server.';
                    reject(error);
                };

                websocket.onclose = () => {
                    console.log('WebSocket connection closed.');
                    if (isRecording) {
                        statusDiv.textContent = 'Connection lost. Please try again.';
                    }
                    stopRecording();
                };
            });
        }

        async function startRecording() {
            if (isRecording) return;
            isRecording = true;

            startButton.disabled = true;
            stopButton.disabled = false;
            thresholdInput.disabled = true;
            pauseDurationInput.disabled = true;
            transcriptionDiv.querySelector('p').textContent = "";

            try {
                await connectWebSocket();

                // Read VAD settings from the sliders
                const positiveSpeechThreshold = parseFloat(thresholdInput.value);
                const pauseDurationMs = parseInt(pauseDurationInput.value);
                // Convert ms to redemptionFrames (VAD frame size is 32ms)
                const redemptionFrames = Math.round(pauseDurationMs / 32);

                console.log(`VAD settings: Threshold=${positiveSpeechThreshold}, Redemption Frames=${redemptionFrames}`);

                const myVad = await vad.MicVAD.new({
                    positiveSpeechThreshold: positiveSpeechThreshold,
                    redemptionFrames: redemptionFrames,

                    onSpeechStart: () => {
                        console.log("Speech started");
                        vadIndicator.classList.add("speaking");
                    },
                    onSpeechEnd: (audio) => {
                        console.log("Speech ended. Sending audio chunk.");
                        vadIndicator.classList.remove("speaking");
                        if (websocket && websocket.readyState === WebSocket.OPEN) {
                            const wavBuffer = vad.utils.encodeWAV(audio);
                            const wavBlob = new Blob([wavBuffer], { type: 'audio/wav' });
                            websocket.send(wavBlob);
                        }
                    },
                });
                micVad = myVad;
                myVad.start();

            } catch (error) {
                console.error('Error starting recording:', error);
                statusDiv.textContent = `Error: ${error.message}`;
                stopRecording();
            }
        }

        function stopRecording() {
            if (!isRecording) return;
            isRecording = false;

            if (micVad) {
                micVad.pause();
                micVad = null;
            }

            if (websocket) {
                websocket.close();
                websocket = null;
            }

            startButton.disabled = false;
            stopButton.disabled = true;
            thresholdInput.disabled = false;
            pauseDurationInput.disabled = false;
            statusDiv.textContent = 'Recording stopped. Press Start to begin again.';
            vadIndicator.classList.remove('speaking');
        }

        startButton.addEventListener('click', startRecording);
        stopButton.addEventListener('click', stopRecording);
    </script>
</body>
</html>

